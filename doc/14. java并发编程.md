
#### 三个并发编程概念

*   原子性问题
    * 原子是世界上的最小单位，具有不可分割性
    * 一个操作是原子操作，那么我们称它具有原子性。

即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。

*   可见性问题

指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

*   有序性问题

即程序执行的顺序按照代码的先后顺序执行。
 

#### Synchronized与ReenTrantLock

两者较大的区别是，synchronized是JVM层面的锁;而ReenTrantLock是jdk提供的API层面的互斥锁，需要lock()和unlock()方法配合try/finally语句块来完成。

1. Synchronized

    Synchronized通过编译，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令。执行monitorenter指令时，首先要尝试获取对象锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象锁，把锁的计算器加一，相应的，在执行monitorexit指令时会将锁计算器减一，当计算器为零时，所就释放了。


    每个对象有一个监视器锁(monitor)。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：
    *    1. 如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。
    *    2. 如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1.
    *    3. ’如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。

    **synchronized锁住的是代码还是对象？**

        synchronized锁住的是对象，同一个对象中的方法在此访问时，并不会申请锁，而是计数加一，所以synchronized是可重入锁。
        


2. ReentrantLock

    ReentrantLock是java.util.concurrent包下提供的一套互斥锁，相比Synchronized，ReentrantLock类提供了一些高级功能，主要有以下3项：
    *    1. 等待可中断，持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待，这相当于Synchronized来说可以避免出现死锁的情况。
    *    2. 公平锁，多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁，但公平锁表现的性能不是很好。
    *    3. 锁绑定多个条件，一个ReentrantLock对象可以同时绑定对个对象。
    *    4. 常见api
        <br>isFair()        //判断锁是否是公平锁
    　　 <br>isLocked()    //判断锁是否被任何线程获取了 
    　　 <br>isHeldByCurrentThread()   //判断锁是否被当前线程获取了 
    　　 <br>hasQueuedThreads()   //判断是否有线程在等待该锁 
 

    ```
    private Lock lock=new ReentrantLock();
    public void run() {
        lock.lock();
        try{
            for(int i=0;i<5;i++)
                System.out.println(Thread.currentThread().getName()+":"+i);
        }finally{
            lock.unlock();
        }
    }
    ```

#### 缓存一致性

解决缓存不一致的问题：

1. 通过在总线加LOCK#锁的方式

    因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问(如内存)，从而使得只能有一个CPU能使用这个变量的内存。

2. 通过缓存一致性协议

    最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。

#### volatile 关键字

1. 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。
2. 禁止进行指令重排序。

但是并不能保证 **原子性**,即：i用volatile修饰,1000个线程调i++,结果并不一定1000.因为自增操作不具备原子性，它包括读取变量的原始值、进行加一操作、写入内存。那么就是说自增操作的三个子操作可能会分割执行。

#### Java原子类

在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增(加1操作)，自减(减1操作)、以及加法操作(加一个数)，减法操作(减一个数)进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的(Compare And Swap)，CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。

    AtomicBoolean 
    AtomicInteger 
    AtomicIntegerArray 
    AtomicIntegerFieldUpdater 
    AtomicLong 
    AtomicLongArray 
    AtomicLongFieldUpdater 
    AtomicMarkableReference 
    AtomicReference 
    AtomicReferenceArray 
    AtomicReferenceFieldUpdater 
    AtomicStampedReference 
    DoubleAccumulator 
    DoubleAdder 
    LongAccumulator 
    LongAdder


- 实现原理

    ```
    /**
        * Atomically increments by one the current value.
        *
        * @return the updated value
        */
        public final int incrementAndGet() {
            for (;;) {
                int current = get();
                int next = current + 1;
                if (compareAndSet(current, next))
                    return next;
            }
        }
    ```
1. 先获取当前的value值 
2. 对value加一 
3. 第三步是关键步骤，调用compareAndSet方法来来进行原子更新操作，这个方法的语义是：

    先检查当前value是否等于current，如果相等，则意味着value没被其他线程修改过，更新并返回true。如果不相等，compareAndSet则会返回false，然后循环继续尝试更新。


#### CAS(Compare-and-Swap)　

CAS算法是由硬件直接支持来保证原子性的，有三个操作数：内存位置V、旧的预期值A和新值B，当且仅当V符合预期值A时，CAS用新值B原子化地更新V的值，否则，它什么都不做。

- CAS的ABA问题

    当然CAS也并不完美，它存在"ABA"问题，假若一个变量初次读取是A，在compare阶段依然是A，但其实可能在此过程中，它先被改为B，再被改回A，而CAS是无法意识到这个问题的。CAS只关注了比较前后的值是否改变，而无法清楚在此过程中变量的变更明细，这就是所谓的ABA漏洞。 

#### 锁相关概念

- 可重入锁

    如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2。 

    ```
    public MyClass{
        public synchronized void method1(){
            method2();
        }
        public synchronized void method2(){

        }
    }
    ```

    机制：每个锁都关联一个请求计数器和一个占有他的线程，当请求计数器为0时，这个锁可以被认为是unhled的，当一个线程请求一个unheld的锁时，JVM记录锁的拥有者，并把锁的请求计数加1，如果同一个线程再次请求这个锁时，请求计数器就会增加，当该线程退出syncronized块时，计数器减1，当计数器为0时，锁被释放。

- 可中断锁

    可中断锁：顾名思义，就是可以相应中断的锁。 

    在Java中，synchronized就不是可中断锁，而Lock是可中断锁。 
    
    如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。 

- 公平锁

    公平锁即尽量以请求锁的顺序来获取锁。比如同是有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程(最先请求的线程)会获得该所，这种就是公平锁。
     
    非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。 
    
    在Java中，synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。

    而对于ReentrantLock和ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁。

    ```
    ReentrantLock lock = new ReentrantLock(true); \\公平锁
    ```
 

- 读写锁

    读写锁将对一个资源(比如文件)的访问分成了2个锁，一个读锁和一个写锁。 
    
    正因为有了读写锁，才使得多个线程之间的读操作不会发生冲突。 
    
    ReadWriteLock就是读写锁，它是一个接口，ReentrantReadWriteLock实现了这个接口。 
    
    可以通过readLock()获取读锁，通过writeLock()获取写锁
 
- 偏向锁

    java偏向锁(Biased Locking)是java6引入的一项多线程优化.它通过消除资源无竞争q情况下的同步原语,进一步提高了程序的运行性能.

    偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在接下来的运行过程中，该锁没有被其他的线程访问，则持有偏向锁的线程将永远不需要触发同步。 

    如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会尝试消除它身上的偏向锁，将锁恢复到标准的轻量级锁。(偏向锁只能在单线程下起作用) 

    因此 流程是这样的 偏向锁->轻量级锁->重量级锁

    偏向锁，简单的讲，就是在锁对象的对象头中有个ThreaddId字段，这个字段如果是空的，第一次获取锁的时候，就将自身的ThreadId写入到锁的ThreadId字段内，将锁头内的是否偏向锁的状态位置1.这样下次获取锁的时候，直接检查ThreadId是否和自身线程Id一致，如果一致，则认为当前线程已经获取了锁，因此不需再次获取锁，略过了轻量级锁和重量级锁的加锁阶段。提高了效率。 
     
 
- 乐观锁，悲观锁

#### 锁的优化策略


#### java线程池

java.util.concurrent.Executors工厂类可以创建四种类型的线程池，通过Executors.new***方式创建
分别为newFiexdThreadPool、newCachedThreadPool、newSingleThreadPool、ScheduledThreadPool

*   newFixedThreadPool 

    ```
    public static ExecutorService newFixedThreadPool(int nThreads){
        return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<Runnable>());
    }
    ```

    创建容量固定的线程池
    阻塞队列采用LinkedBlockingQueue (poll()、take()),它是一种无界队列
    由于阻塞队列是一个无界队列，因此永远不可能拒绝执行任务
    由于采用无界队列，实际线程数将永远维持在nThreads,因此maximumPoolSize和KeepAliveTime将无效

*   newCachedThreadPool

    ```
    public static ExecutorService newCachedThreadPool(){
        return new ThreadPoolExecutor(0, Interger.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue<Runnable>());
    }
    ```

    CachedThreadPool是一种可以无限扩容的线程池
    CachedThreadPool比较适合执行时间片较小的任务
    KeepAliveTime为60，意味着线程空闲时间超过60秒就会被杀死
    阻塞队列采用SynchronousQueue,这种阻塞队列没有存储空间，意味着只要有任务到来，就必须得有一个工作线程进行处理，如果当前没有空闲线程，就新建一个线程

*   SingleThreadExecutor

    ```
    public static ExecutorService newSingleExecutor(){
        return new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLSECONDS, new LinkedBlockingQueue<Runnable>());
    }
    ```

    SingleThreadExecutor 只会创建一个工作线程来处理任务

*   ScheduledThreadPool接收ScheduleFutureTask类型的任务，提交任务的方式有两种
    1. scheduledAtFixedRate 
    2. scheduledWithFixedDelay
    - SchduledFutureTask接收参数： 
        time：任务开始时间 
        sequenceNumber：任务序号 
        period：任务执行的时间间隔 
    - 阻塞队列采用DelayQueue，它是一种无界队列
    - DelayQueue内部封装了一个PriorityQueue，它会根据time的先后排序，若time相同，则根据sequenceNumber排序
    - 工作线程执行流程： 
        1. 工作线程会从DelayQueue中取出已经到期的任务去执行
        2. 执行结束后重新设置任务的到期时间，再次放回DelayQueue。

